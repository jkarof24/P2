\subsection{Statistical Methods}
This section will present statistical methods to evaluate the reliability and significance of a regression model. The focus will be on confidence intervals and hypothesis testing, these are two methods that can access the models uncertainty and determine whether observed effects are random. The confidence interval is used to determine an interval which likely include a value of a parameter with a chosen level of confidence. A hypothesis test is used to determine if there is enough statistical evidence to reject a null hypothesis with a chosen significance level.

\subsubsection{Confidence Intervals}
The confidence interval is a good tool to use when trying to estimate a parameter of a population. Its used to create an interval, where the parameter has a probability to be inside of. This probability is called the confidence level and it is a chosen value, usually the chosen confidence level is either 95\% or 99\%. The confidence interval will become bigger with a smaller confidence level. A good confidence interval is small with a large confidence level, this will usually occur when the sample size is large. The chosen confidence level relates to an $\alpha$-value, where, as an example, the chosen confidence level is 95\%, then the $\alpha$-value would be 5\% or normally written as $0.05$. The $\alpha$-value is used to determine the critical value, which is used to calculate the margin of error. For example, it is used when trying to find the critical value of the confidence interval, when working with a t-distribution.
\newline

\noindent To set up a confidence interval, the margin of error needs to be computed and then both will be added and subtracted from the point estimate. This will give the values of the outer bounds of the interval. The margin of error is calculated from this formula:
\begin{equation}
	\text{Margin of Error} = \text{Critical Value } \pm \text{Standard Error}.
\end{equation}

\noindent The standard error will change depending on which parameter that the confidence interval is estimating, but the general formula for the standard error is:
\begin{equation}
	\frac{\sigma}{\sqrt{n}}
\end{equation}

\noindent Where $\sigma$ is the standard deviation and $n$ is the amount of observations. An example of computing a confidence interval of the mean while working with a standard normal distribution, then the formula for the confidence interval would be this:
\begin{equation}
P(-z_{\alpha/2}<Z<z_{\alpha/2}) = 1-\alpha
\end{equation}

\noindent Where $1-\alpha$ is the confidence level. As it is the mean that is being estimated, then instead of Z-score, then $\mu$ must be isolated and that is done by multiplying $\frac{\sigma}{\sqrt{n}}$ and subtracting $\bar{X}$ on all sides, then multiplying all side by $-1$ to remove the minus sign. So the formula for a confidence interval of the mean will look like this:
\begin{equation}
P(\bar{X}-z_{\alpha/2}\frac{\sigma}{\sqrt{n}}<\mu<\bar{X}+z_{\alpha/2}\frac{\sigma}{\sqrt{n}})=1-\alpha
\end{equation}

\noindent This formula will give the upper and lower bounds of the confidence interval.\\

\noindent \textbf{The interpretation of a confidence interval}
\newline
To interpret a confidence interval, it would be incorrect to interpret the confidence level of some value $x$, as the probability of the true parameter being inside of the interval. The reason behind this, is that the computed interval is static, so either the value $x$ is inside the interval or it is not. So the correct way of interpreting the confidence interval is by taking multiple samples and computing the confidence interval for all samples, then the value $x$ would reside inside 95\% of the confidence intervals.\cite{ProbAndStat_8th}


\subsubsection{Hypothesis Testing}
A hypothesis test is used to test an assumption about a population. This is done from a sample of the population, as the information about the population is usually hard to come by. A hypothesis test is set up, by having a null hypothesis and an alternate hypothesis.
$$H_0 = \text{Null hypothesis}$$
$$H_a = \text{Alternate hypothesis}$$
When working with hypothesis testing, the hypothesis $H_0$ is usually represented as the status quo, where the hypothesis $H_a$ is represented as an alternate hypothesis. It is also important to note that there is only two outcomes of a hypothesis test, either $H_0$ is rejected in favor of $H_a$ or $H_0$ is failed to be rejected. Therefore in no situation can $H_0$ be stated to be an absolute truth, as there might be other samples where $H_0$ will be rejected. Therefore, in a hypothesis test $H_0$ needs to be the thing that can be rejected and if $H_0$ gets rejected, then $H_a$ will become the new status quo until proven otherwise.\\
In a hypothesis test $H_0$ will be the assumption that a parameter for two populations is the same, where as $H_a$ can be either one of three assumptions, depending on the intention of the hypothesis test.
$$H_0: \theta = \theta_0$$
$$1.\;H_a: \theta \neq \theta_0$$
$$2.\;H_a: \theta < \theta_0$$
$$3.\;H_a: \theta > \theta_0$$
When the direction of the rejection is not important and also is unknown, then (1) will be the case. This scenario sets up a two-tailed-test, where the hypothesis test is used to reject $H_0$ if $H_a$ is either significantly larger or smaller than $H_0$, this means that the critical area is on both sides of the difference of $\theta$ and $\theta_0$. Either (2) or (3) will set up a one-tailed-test, where, depending on what is important, either the hypothesis test is used to determine if $H_a$ is significantly bigger or smaller than $H_0$. This means that the critical area only spans one side of the difference between $\theta$ and $\theta_0$.\\


\noindent \textbf{Error in hypothesis testing}
\newline
When making a hypothesis test, there is four different possible outcomes. The results are separated by correct decisions and errors. There exists two types of hypothesis errors called type 1 error and type 2 error. The type 1 error occurs when $H_0$ is mistakenly rejected and $H_0$ is true. Type 2 error is the opposite, where $H_a$ is rejected and $H_a$ is true. The types of outcomes occurring from a hypothesis test can be seen in Table \ref{tab:example2x3}
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		 & $H_0$ is true & $H_0$ is false \\
		\hline
		Does not reject $H_0$ & Correct decision & Type 2 error \\ \hline
		Reject $H_0$ & Type 1 error & Correct decision \\
		\hline
	\end{tabular}
	\caption{Outcomes of a hypothesis test}
	\label{tab:example2x3}
\end{table}

\noindent It is possible to compute the probability of a type 1 error occurring, this value is the same as the significance level $\alpha$. To calculate the probability of a type 2 error occurring, the $H_a$ needs to be defined, or more specifically, the mean of the sample is needed. Depending on which parameter is known, different formulas are taken into use. As an example, where the standard deviation is known, it is a normal distribution and it is a one tailed test, then the formula for the Z-score is used, but $\overline{X}$ is exchanged with $\overline{x}_{crit}$ and $\mu$ is exchanged with $\mu_1$:

\begin{equation}
Z=\frac{\overline{x}_{crit}-\mu_1}{\sigma/\sqrt{n}}
\end{equation}


\noindent The value of $\overline{x}_{crit}$ is the value, that separates whether $H_0$ is rejected or not, and $\mu_1$ is the value of the alternative hypothesis.
The value of the calculated Z-score is used in a table of areas under the normal curve. This value will be used as the probability of a type 2 error occurring.


