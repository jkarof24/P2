In this project, synthetic data was used to demonstrate the effect of violating the assumption of homoscedasticity on polynomial regression from the ordinary least squares method, and polynomial regression from Monte Carlo Bootstrapping. The results show that the bootstrap model exhibits superior predictive accuracy, as evidenced by its lower RMSE. It is 1350.7740 for the bootstrap, and 1884.5830 for OLS, it also has a smaller MBE, 17.7164 for the bootstrapped model and -546.4660 for the OLS model. Furthermore, the standard errors and confidence intervals produced by the OLS model are shown to be unreliable, whereas those from the bootstrap method are more trustworthy, as they are based on the empirical variation in the data. it has been shown that the $R^2$ is also unreliable when it comes to hetroscedastic data and how the bootstraps $R^2$ destitution and confidence-intervals can showcase the reliability of the $R^2$ metric. Overall, the bootstrap approach proves to be excellent in terms of predictive power and robustness, especially in cases where the data is homoscedastic.\\

\noindent The project has provided information about how bootstrapping can solve issues created from violating assumptions needed for a reliable polynomial model. Since these assumptions are easily violated in real-life data, we now have insight in the bootstrapping method, that can help make the process of creating a polynomial regression model both easier and more accurate. 