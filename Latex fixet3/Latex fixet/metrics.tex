\subsection{Metrics}
To evaluate the quality of a regression model, various metrics are used. Each metric provides a score that reflects the reliability of the model's predictions. Sections through are based on 'Performance Metrics (Error Measures) in Machine Learning Regression, Forecasting and Prognostics: Properties and Typology'\cite{metrics}. \newline

\noindent Metrics are measures used to evaluate how well a model performs. Metrics assess the accuracy of the model’s predictions compared to actual values. Common metrics like The Coefficient of Determination ($R^{2}$) and Mean Bias Error (MBE) help determine how closely predictions match real outcomes, while others like bias and variance reveal systematic errors and model stability. Metrics help model selection and improvement by providing objective feedback on performance. They’re essential for comparing models, detecting underfitting or overfitting, and ensuring predictions are reliable for real-world use.
\\\\

\subsubsection{The Coefficient of Determination}
% What is it?
$R^2$ measures how much better the model predicts outcomes compared to simply using the mean. It is calculated using the Total Sum of Squares (TSS) and the Sum of Squared Errors (SSE) with this formula: 
\begin{equation}
R^2=1-\frac{\text{SSE}}{\text{TSS}}
\end{equation}

\noindent TSS explains how much the values of a dataset vary from the mean and is calculated by: 
\begin{equation}
\sum_{j=1}^{n}(A_j - \bar{A})^2,
\end{equation}
where $A_j$ is the actual value and $\hat{A}$ is the mean of all actual values.
\\\\

\noindent The SSE is how far the predictions from the model are from the actual values and is calculated by:
\begin{equation}
	\sum_{j=1}^{n}(A_j - P_j)^2,
\end{equation}
where $A_J$ is the actual value, $P_j$ is the predicted value, and $n$ is the number of observations \cite{metrics}. The errors are squared to make all values positive, highlight larger mistakes more strongly, and stay consistent with how variance is calculated in statistics.
\\\\
% Interpretation
$R^2$ explains how much of the variance explained by the model. The value of $R^2$ typically lies in the range $0 \leq R^2 \leq 1$, where 0 means that the model explains none of the variance, a value of 1 would mean that the model explains all the variance, while 0.5 means that the model explains 50\% of the variance. If the value of $R^2$ is negative, it means that the model is performing so poorly that it would be better to simply predict the mean for all observations.

\noindent Although widely used, the $R^2$-score should not be relied upon as the only metric of model performance due to several shortcomings. Primarily, it evaluates the proportion of variance in the dependent variable explained by the model, but does not reflect the accuracy of individual values. As a result, a model can achieve a high $R^2$ despite making major errors on specific data points. In addition, $R^2$ is vulnerable to overfitting, especially when the model becomes overly complex and starts fitting the noise in the data instead of underlying trends. Another critical issue is that $R^2$ does not adjust for the number of predictors in the model. It will never decrease when more features are added, even if those features are irrelevant. For a more reliable assessment, alternative metrics should be used alongside $R^2$ to evaluate a regression model. 
\newpage

\subsubsection{Mean Bias Error}
Mean Bias Error (MBE) is a metric that measures the average difference between the actual values and the model's predictions. Unlike other metrics, MBE does not emphasize the magnitude of the error but instead indicates whether the model systematically overestimates or underestimates, revealing potential bias in the predictions. \newline 

\noindent The formula for MBE is:

\begin{equation}
\text{MBE}=\frac{1}{n}\sum_{j=1}^{n}(e_{j}).
\end{equation}
\noindent Here $e_{j}=A_{j}-P_{j}$, again $P_{j}$ is the predicted value, $A_{j}$ is the actual value, and $n$ is the number of observations \cite{metrics}.
\\\\

\noindent When interpreting MBE, there are three different cases to consider. If the $\text{MBE}\geq 0$, the model tends to over-predict the values compared to the actual values. If the $\text{MBE}\leq0$, the opposite is the case, and the model tends to under-predict the values. If the $\text{MBE}\approx0$ there is no consistent bias in either direction.
\\

\noindent The MBE measures the bias of the model, whether it tends to predict values that are generally too high or too low compared to the actual values. This means that we cannot use MBE to estimate the size of the error or the overall quality of the model. If two actual values are $100$ and the model predicts $120$ and $80$ the error calculated with $\hat{y}-y$ is $+20$ and $-20$. Because the absolute or squared values are not used, these errors will cancel each other out. Therefore, the size of the error is not computed. Instead, to understand the size of the errors, Root Mean Square Error (RMSE) can be used, which penalizes large deviations more heavily.

\newpage

\subsubsection{Root Mean Square Error}   

RMSE is a metric used to evaluate regression models. It measures the average size of prediction errors. Since it squares the errors, it punishes larger errors more than smaller ones, which is useful if the objective is to emphasize the impact of larger deviations of the actual values.
\\
The formula for RMSE:
\begin{equation}
	\text{RMSE}=\sqrt{\frac{ \sum_{j=1}^{n} e_j^2 }{n}}.
\end{equation}
As before, $e_{j}=A_{j}-P_{j}$, where $P_{j}$ is the predicted value, $A_{j}$ is the actual value, and $n$ is the number of observations \cite{metrics}.
\\ The idea is to find the error by subtracting the actual value from its prediction, square the error so negatives and positives do not cancel out,like in MBE, and large errors will stand out. Then the average of all squared errors is found, and the square root is taken to bring the result back to the original scale. 
\\

\noindent The RMSE is always a non-negative number, and the closer RMSE is to 0, the better the model is performing. The scale and unit of RMSE is the same as the target variable. So, if the data is about 'Miles Per Gallon', a RMSE of 2 means that the predictions of the model are 2 miles off, on average. Therefore, RMSE is most useful when the objective is comparing different models on the same dataset, or at least on datasets with the same scale, and in the same units. This also means an RMSE of 5 can be great if the values of the target variable range from 1-1000, but awful if the range is 1-10. Like the other metrics, RMSE should be used alongside other metrics to provide a more complete picture of the model’s performance. RMSE does not explain why a model performs well or poorly. To understand why a model performs poorly, bias-variance decomposition can be used to split error into systematic bias and model instability.
\newpage

\subsubsection{Confidence Intervals}
Confidence intervals are used in model evaluation to judge the stability and reliability of a model's estimations. Unlike the previously mentioned metrics, confidence intervals do not provide a single number, but instead a range within which the true parameter value is likely to lie, given a specified level of confidence. The level of confidence is typically 95\%. \newline 

\noindent By comparing overlap and width of the confidence intervals across different models, it is possible to assess which model generates the best estimates, based on consistency and reliability.